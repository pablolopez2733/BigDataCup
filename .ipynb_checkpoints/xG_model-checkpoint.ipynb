{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import clean_data\n",
    "\n",
    "\n",
    "def get_roc(actual, predictions):\n",
    "    \"\"\"\n",
    "    Get the roc curve (and auc score) for the different models\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    plt.title('ROC Curves')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "\n",
    "    colors = ['b', 'g', 'p']\n",
    "\n",
    "    for model, color in zip(predictions.keys(), colors):\n",
    "        # Convert preds to just prob of goal\n",
    "        preds = [pred[1] for pred in predictions[model]]\n",
    "\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(actual, preds)\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        plt.plot(false_positive_rate, true_positive_rate, label=' '.join([model + ':', str(round(roc_auc, 3))]))\n",
    "\n",
    "    # Add \"Random\" score\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label=' '.join([\"Random:\", str(.5)]))\n",
    "\n",
    "    plt.legend(title='AUC Score', loc=4)\n",
    "    fig.savefig(\"ROC_xG.png\")\n",
    "\n",
    "\n",
    "def fit_gradient_boosting(features_train, labels_train):\n",
    "    \"\"\"\n",
    "    Fit a gradient boosting algorithm and use cross validation to tune the hyperparameters\n",
    "    :return: classifier\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'min_samples_split': [100, 250, 500],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    }\n",
    "\n",
    "    clf = GradientBoostingClassifier(n_estimators=500, learning_rate=.1, random_state=42, verbose=2)\n",
    "\n",
    "    print(\"Fitting Gradient Boosting Classifier\")\n",
    "\n",
    "    # Tune hyperparameters\n",
    "    cv_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv=10)\n",
    "\n",
    "    # Fit classifier\n",
    "    cv_clf.fit(features_train, labels_train)\n",
    "\n",
    "    print(\"\\nGradient Boosting Classifier:\", cv_clf)\n",
    "\n",
    "    # Save model\n",
    "    pickle.dump(cv_clf, open(\"gmb_multiclass_xg.pkl\", 'wb'))\n",
    "\n",
    "    return cv_clf\n",
    "\n",
    "\n",
    "def fit_random_forest(features_train, labels_train):\n",
    "    \"\"\"\n",
    "    Fit random forest and use cross validation to tune the hyperparameters\n",
    "    :return: classifier\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'min_samples_leaf': [50, 100, 250, 500]\n",
    "    }\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, verbose=2)\n",
    "\n",
    "    # Tune hyperparameters\n",
    "    cv_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv=10)\n",
    "\n",
    "    print(\"Fitting Random Forest\")\n",
    "\n",
    "    cv_clf.fit(features_train, labels_train)\n",
    "    print(\"\\nRandom Forest Classifier:\", cv_clf)\n",
    "\n",
    "    # Save model\n",
    "    pickle.dump(cv_clf, open(\"rf_rebounds_xg.pkl\", 'wb'))\n",
    "    return cv_clf\n",
    "\n",
    "\n",
    "def fit_logistic(features_train, labels_train):\n",
    "    \"\"\"\n",
    "    Fit the logistic regression and use cross validation to tune the hyperparameters\n",
    "    :return: classifier\n",
    "    \"\"\"\n",
    "    print(\"Fitting Logistic\")\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "    }\n",
    "\n",
    "    clf = LogisticRegression(penalty='l2', solver='sag', random_state=42, max_iter=10000, tol=.01)\n",
    "\n",
    "    # Tune hyperparameters\n",
    "    cv_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv=10)\n",
    "\n",
    "    # Fit classifier\n",
    "    cv_clf.fit(features_train, labels_train)\n",
    "\n",
    "    print(\"\\nLogistic Regression Classifier:\", cv_clf)\n",
    "\n",
    "    # Save model\n",
    "    pickle.dump(cv_clf, open(\"logistic_xg.pkl\", 'wb'))\n",
    "\n",
    "    return cv_clf\n",
    "\n",
    "\n",
    "def xg_model():\n",
    "    \"\"\"\n",
    "    Create and test xg model.\n",
    "    \n",
    "    Fit three different models (Refer to those specific functions for more info):\n",
    "    1. Logistic regression\n",
    "    2. Gradient Boosting\n",
    "    3. Random Forest\n",
    "    \"\"\"\n",
    "    data = clean_data.get_data()\n",
    "\n",
    "    data['Outcome'] = np.where(data['Outcome'] == 0, 0, np.where(data['Outcome'] == 1, 0, np.where(data['Outcome'] == 2, 1, 3)))\n",
    "    data = data[data['Outcome'] != 3]\n",
    "\n",
    "    # Convert to lists\n",
    "    features, labels = clean_data.convert_data(data)\n",
    "\n",
    "    # Split into training and testing sets -> 80/20\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=.2, random_state=42)\n",
    "\n",
    "    # Fix Data\n",
    "    features_train, labels_train = np.array(features_train), np.array(labels_train).ravel()\n",
    "\n",
    "    ###### FIT MODELS\n",
    "    log_clf = fit_logistic(features_train, labels_train)\n",
    "    gb_clf = fit_gradient_boosting(features_train, labels_train)\n",
    "    rf_clf = fit_random_forest(features_train, labels_train)\n",
    "\n",
    "    #### Testing\n",
    "    log_preds_probs = log_clf.predict_proba(features_test)\n",
    "    gb_preds_probs = gb_clf.predict_proba(features_test)\n",
    "    rf_preds_probs = rf_clf.predict_proba(features_test)\n",
    "\n",
    "    # Convert test labels to list instead of lists of lists\n",
    "    flat_test_labels = [label[0] for label in labels_test]\n",
    "\n",
    "    ### LOG LOSS\n",
    "    print(\"\\nLog Loss: \")\n",
    "    print(\"Logistic Regression: \", log_loss(flat_test_labels, log_preds_probs))\n",
    "    print(\"Gradient Boosting: \", log_loss(flat_test_labels, gb_preds_probs))\n",
    "    print(\"Random Forest: \", log_loss(flat_test_labels, rf_preds_probs))\n",
    "\n",
    "    ### ROC\n",
    "    preds = {\n",
    "        \"Random Forest\": rf_preds_probs,\n",
    "        \"Gradient Boosting\": gb_preds_probs,\n",
    "        \"Logistic Regression\": log_preds_probs\n",
    "    }\n",
    "    get_roc(flat_test_labels, preds)\n",
    "\n",
    "\n",
    "def main():\n",
    "    xg_model()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
